import os
import re
import csv
from bs4 import BeautifulSoup
from unidecode import unidecode

#====================================================
# üîπ Diccionarios y listas para almacenar entidades y relaciones
#====================================================

empresas = {}
puestos = {}
ubicaciones = {}
idiomas_almacenados = {}
habilidades_tecnicas = {}
habilidades_blandas = {}
especialidades = {}
tiempos = {}

ofertas_laborales = []
oferta_habilidad_tecnica = []
oferta_habilidad_blanda = []
oferta_idioma = []

# =========================================
# üîπ Carpeta donde est√°n los archivos HTML
# =========================================
carpeta_ofertas = "data/2022"
archivo_csv = "ofertas_laborales.csv"

if not os.path.exists(carpeta_ofertas):
    print(f"‚ùå La carpeta '{carpeta_ofertas}' no existe. Verifica la ruta.")
    exit()


#=========================================
# üîπ Lista de palabras vac√≠as (para limpiar textos)
#=========================================

palabras_a_descartar = [
    "si", "para", "como", "a", "de", "y", "o", "con", "por", "el", "la", "en", "los", "las", "que", "un", "una",
    "su", "del", "al", "se", "m√°s", "es", "son", "no", "sobre", "entre", "hasta"
]

lista_especialidades = ["Licenciado/a Bioinform√°tico","Lic. Bioinformatico","Bioinform√°tica","Licenciado/a","Licendiado","Licenciada", "Bioingeniero/a","Bioingeniero","Bioingeniera","Bioingenier√≠a","Ingenier√≠a Biom√©dica"
                        "Biotecnolog√≠a","Ingenier√≠a", "Ingeniero","Ingeniero en Transporte", "Ing. en Transporte","T√©cnico","Tecnico","Tecnico en Procesamiento de Datos","Ciencia de Datos","Desarrollo de Software"]

mapeo_habilidades = {
    # Habilidades t√©cnicas
    "inform√°tica": "T√©cnica",
    "programaci√≥n": "T√©cnica",
    "software": "T√©cnica",
    "bases de datos": "T√©cnica",
    "sql": "T√©cnica",
    "python": "T√©cnica",
    "c": "T√©cnica",
    "c++": "T√©cnica",
    "powerbi": "T√©cnica",
    "ingenieria biom√©dica": "T√©cnica",
    "bioingeniero": "T√©cnica",
    "bioinform√°tico": "T√©cnica",
    "t√©cnico": "T√©cnica",
    "ingeniero": "T√©cnica",
    "licenciado": "T√©cnica",
    "analista": "T√©cnica",
    "desarrollador": "T√©cnica",
    "autocad": "T√©cnica",
    "curso auditor": "T√©cnica",
    "herramientas inform√°ticas": "T√©cnica",
    "herramientas de electr√≥nica": "T√©cnica",
    "manejo de herramientas de oficina": "T√©cnica",
    "manejo de equipos": "T√©cnica",
    "iso 9000": "T√©cnica",
    "iso 13485": "T√©cnica",
    "redes": "T√©cnica",
    "manejo maquinarias": "T√©cnica",
    "manejo de maquinaria de estetica": "T√©cnica",
    "manejo de maquinaria industrial": "T√©cnica",
    "manejo de maquinaria agr√≠cola": "T√©cnica",
    "manejo de maquinaria hospitalaria": "T√©cnica",
    "planos esquem√°ticos": "T√©cnica",
    "manejo de t√©cnicas estad√≠sticas": "T√©cnica",
    "reparaci√≥n de equipos": "T√©cnica",
    "experiencia en reparaci√≥n de equipos": "T√©cnica",
    
    # Habilidades blandas
    "experiencia": "Blanda",
    "comunicaci√≥n": "Blanda",
    "trabajo en equipo": "Blanda",
    "liderazgo": "Blanda",
    "empat√≠a": "Blanda",
    "proactividad": "Blanda",
    "capacidad de gesti√≥n": "Blanda",
    "perfil comercial": "Blanda",
    "trabajo interdisciplinario": "Blanda",
    "capacidad de an√°lisis": "Blanda",
    "capacidad de organizaci√≥n": "Blanda",
    "capacidad de resoluci√≥n de problemas": "Blanda",
    "capacidad de aprendizaje": "Blanda",
    "capacidad de adaptaci√≥n": "Blanda",
    "capacidad de trabajo bajo presi√≥n": "Blanda",
    "capacidad de comunicaci√≥n": "Blanda",
    "capacidad de liderazgo": "Blanda",
    "capacidad de negociaci√≥n": "Blanda",
    "capacidad de planificaci√≥n": "Blanda",
    "orientaci√≥n al cliente": "Blanda",
    "orientaci√≥n a resultados": "Blanda",
    "resoluci√≥n de problemas": "Blanda",
    "docencia": "Blanda",
    "disponibilidad horaria": "Blanda",
    "disponibilidad para viajar": "Blanda"
}


# Lista de frases irrelevantes para filtrar
frases_ignoradas = [
    "B√∫squedas Laborales FIUNER",
    "Facultad de Ingenier√≠a - Universidad Nacional de Entre R√≠os",
    "contacto@ingenieria", 
    "Tel:", 
    "Se distribuye a m√°s de", 
    "¬© Copyright"
]
#===================================================
# üîπ Lista ampliada de ciudades de Argentina y pa√≠ses lim√≠trofes
#===================================================
ciudades = [

    # Buenos Aires
    "AMBA", "Buenos Aires", "La Plata", "Mar del Plata", "Bah√≠a Blanca", "Tandil", "San Nicol√°s", "Pergamino", "Olavarr√≠a",
    # CABA
    "CABA", "Ciudad Aut√≥noma de Buenos Aires",
    # C√≥rdoba
    "C√≥rdoba", "Cordoba", "Villa Carlos Paz", "R√≠o Cuarto", "Villa Mar√≠a", "Alta Gracia", "San Francisco",
    # Santa Fe
    "Rosario", "Santa Fe", "Rafaela", "Venado Tuerto", "Reconquista", "Villa Gobernador G√°lvez",
    # Mendoza
    "Mendoza", "San Rafael", "Godoy Cruz", "Maip√∫", "Las Heras",
    # Entre R√≠os
    "Paran√°", "Concordia", "Gualeguaych√∫", "Gualeguay", "Victoria", "Col√≥n", "Diamante", "Oro Verde"
    # Salta
    "Salta", "Tartagal", "Cafayate", "Or√°n", "San Ram√≥n de la Nueva Or√°n",
    # Tucum√°n
    "San Miguel de Tucum√°n", "Yerba Buena", "Taf√≠ Viejo", "Concepci√≥n", "Monteros",
    # Neuqu√©n
    "Neuqu√©n", "San Mart√≠n de los Andes", "Villa La Angostura", "Zapala",
    # R√≠o Negro
    "Viedma", "San Carlos de Bariloche", "General Roca", "Cipolletti",
    # Chaco
    "Resistencia", "Roque S√°enz Pe√±a", "Villa √Ångela", "Charata",
    # Misiones
    "Posadas", "Eldorado", "Ober√°", "Puerto Iguaz√∫",
    # Corrientes
    "Corrientes", "Goya", "Paso de los Libres", "Mercedes",
    # Chubut
    "Rawson", "Comodoro Rivadavia", "Trelew", "Puerto Madryn",
    # Jujuy
    "San Salvador de Jujuy", "Palpal√°", "Libertador General San Mart√≠n",
    # San Juan
    "San Juan", "Rivadavia", "Chimbas", "Pocito",
    # San Luis
    "San Luis", "Villa Mercedes", "La Punta",
    # Catamarca
    "San Fernando del Valle de Catamarca", "Bel√©n", "Tinogasta",
    # La Rioja
    "La Rioja", "Chilecito",
    # Santa Cruz
    "R√≠o Gallegos", "Caleta Olivia", "El Calafate",
    # Tierra del Fuego
    "Ushuaia", "R√≠o Grande",
    # Formosa
    "Formosa", "Clorinda",
    # La Pampa
    "Santa Rosa", "General Pico",
    # Santiago del Estero
    "Santiago del Estero", "La Banda", "Termas de R√≠o Hondo",
    # Pa√≠ses Lim√≠trofes
    # Bolivia
    "Bolivia", "La Paz", "Cochabamba", "Santa Cruz", "Sucre", "Oruro", "Potos√≠", "Tarija",
    # Chile
    "Chile", "Santiago", "Valpara√≠so", "Concepci√≥n", "La Serena", "Antofagasta", "Temuco", "Rancagua", "Iquique", "Punta Arenas",
    # Paraguay
    "Paraguay", "Asunci√≥n", "Ciudad del Este", "Encarnaci√≥n", "San Lorenzo", "Luque",
    # Uruguay
    "Uruguay", "Montevideo", "Salto", "Paysand√∫", "Maldonado", "Rivera", "Canelones",
    # Brasil
    "Brasil", "Sao Paulo", "Rio de Janeiro", "Brasilia", "Porto Alegre", "Curitiba", "Florian√≥polis", "Recife", "Fortaleza"
]

# Lista de idiomas comunes
idiomas = ["Ingl√©s", "Espa√±ol", "Franc√©s", "Portugu√©s", "Alem√°n", "Italiano", "Chino", "Japon√©s"]

# ===========================================
# üîπ Funciones de Extracci√≥n y Limpieza
# ===========================================

def extraer_titulos_puesto(soup):
    """ Extrae todos los t√≠tulos de puesto encontrados. """
    titulos = [h4.get_text(strip=True) for h4 in soup.find_all('h4')]
    return titulos if titulos else ["Puesto no especificado"]

def extraer_empresa(soup):
    """ Extrae el nombre de la empresa evitando capturar frases irrelevantes. """
    texto = soup.get_text().replace("\n", " ")  # Quitamos saltos de l√≠nea innecesarios
    
    # Patrones mejorados para detectar nombres de empresa
    patrones_empresa = [
        r'(?:Empresa|Instituto|Organizaci√≥n|Laboratorio|Fundaci√≥n|Universidad|Instituci√≥n|Compa√±√≠a)\s*[:\-]?\s*([A-Z][\w\s&.,-]+)',
        r'busca\s+([A-Z][\w\s&.,-]+)',   # "Se busca X"
        r'convoca\s+([A-Z][\w\s&.,-]+)', # "Convoca a X"
        r'ofrece\s+([A-Z][\w\s&.,-]+)',  # "Ofrece X"
        r'para\s+([A-Z][\w\s&.,-]+)',    # "Para empresa X"
    ]

    for patron in patrones_empresa:
        match = re.search(patron, texto, re.IGNORECASE)
        if match:
            empresa = match.group(1).strip()
            if 2 < len(empresa.split()) < 7:  # Aseguramos que no sea una frase demasiado larga
                return empresa

    return "Empresa no especificada"


def extraer_ciudad(texto):
    """ Busca ciudades en el texto y devuelve la primera encontrada. """
    for ciudad in ciudades:
        if re.search(rf"\b{ciudad}\b", texto, re.IGNORECASE):
            return ciudad
    return "Ciudad no especificada"

def extraer_fecha(soup):
    """Busca la fecha de publicaci√≥n en el texto y la devuelve en formato limpio."""
    match = re.search(r'\d{1,2}\s+de\s+\w+\s+de\s+\d{4}', soup.get_text())
    return match.group(0).replace("\n", " ") if match else "Fecha no especificada"


def extraer_especialidad(texto):
    """ Busca especialidades en el texto y devuelve la primera encontrada. """
    for especialidad in lista_especialidades:
        if re.search(rf"\b{especialidad}\b", texto, re.IGNORECASE):
            return especialidad
    return "Especialidad no especificada"

def extraer_idioma(texto):
    """ Busca idiomas mencionados en el texto y devuelve el primero encontrado. """
    for idioma in idiomas:
        if re.search(rf"\b{idioma}\b", texto, re.IGNORECASE):
            return idioma
    return "Idioma no especificado"


def extraer_habilidades(texto):
    """ Extrae habilidades t√©cnicas y blandas, evitando falsos positivos. """
    habilidades_detectadas = []
    texto_limpio = unidecode(texto.lower())

    # Identifica secciones clave donde suelen mencionarse habilidades
    secciones = re.findall(
        r'(?:requisitos|habilidades|perfil requerido|conocimientos requeridos):([\s\S]+?)(?:\n[A-Z]|\Z)',
        texto_limpio,
        re.IGNORECASE
    )
    contenido_relevante = " ".join(secciones) if secciones else " ".join(texto_limpio.split()[:500])

    for patron, tipo in mapeo_habilidades.items():
        if patron in ["c", "c++"]:
            # Solo acepta si est√°n bien delimitadas (no parte de otra palabra)
            if re.search(rf"\b{patron}\b", contenido_relevante):  
                habilidades_detectadas.append((patron, tipo))
        else:
            if re.search(rf"\b{re.escape(patron)}\b", contenido_relevante):
                habilidades_detectadas.append((patron, tipo))

    return habilidades_detectadas if habilidades_detectadas else [("Habilidades no especificadas", "N/A")]


# =========================================
# üîπ Funci√≥n para extraer datos de un HTML
# =========================================

def procesar_html(ruta_archivo):
    print(f"üìÑ Procesando: {ruta_archivo}")

    try:
        with open(ruta_archivo, 'r', encoding='utf-8', errors='ignore') as archivo:
            contenido_html = archivo.read()

        if not contenido_html.strip():
            print(f"‚ö†Ô∏è Archivo vac√≠o, omitiendo: {ruta_archivo}")
            return None  # üîπ Ahora devolvemos None si el archivo est√° vac√≠o

        soup = BeautifulSoup(contenido_html, 'html.parser')
        texto_completo = soup.get_text(separator=" ").lower()

        # üîπ Extraer empresa
        patrones_empresa = [
            r"(?:empresa|instituto|organizaci√≥n|laboratorio|fundaci√≥n|universidad|instituci√≥n|compa√±√≠a|beca|posgrado|vacante|oferta)[:\s]?([\w\s&.,-]+)",
            r"buscamos ([A-Z][\w\s&.,-]+)",  
            r"convoca a ([A-Z][\w\s&.,-]+)",  
            r"para empresa ([A-Z][\w\s&.,-]+)",  
            r"se solicita en ([A-Z][\w\s&.,-]+)",  
        ]
        empresa = "No especificada"
        for patron in patrones_empresa:
            match = re.search(patron, texto_completo, re.IGNORECASE)
            if match:
                empresa = match.group(1).strip().title()
                empresa = " ".join(empresa.split()[:5])  # Limitar a 5 palabras
                break

        # üîπ Extraer ciudad
        ciudad = next((c for c in ciudades if re.search(rf"\b{c.lower()}\b", texto_completo)), "No especificada")

        # üîπ Extraer fecha
        patrones_fecha = [
            r"(\d{1,2} de [a-z]+ de \d{4})",  # "4 de octubre de 2022"
            r"(\d{1,2}/\d{1,2}/\d{4})",  # "29/9/2022"
            r"(\d{4}-\d{2}-\d{2})"  # "2022-10-04"
        ]
        fecha = "No especificada"
        for patron in patrones_fecha:
            match_fecha = re.search(patron, texto_completo, re.IGNORECASE)
            if match_fecha:
                fecha = match_fecha.group(0)
                break

        # üîπ Extraer t√≠tulo del puesto
        titulo_puesto = soup.find('h4').get_text(strip=True) if soup.find('h4') else "No especificado"

        # üîπ Extraer habilidades
        habilidades_encontradas = []
        for habilidad, tipo in mapeo_habilidades.items():
            if habilidad in texto_completo:
                habilidades_encontradas.append(f"{habilidad} ({tipo})")

        # üîπ Devolver los datos como una tupla
        return [empresa, titulo_puesto, ciudad, fecha, ", ".join(habilidades_encontradas)]

    except Exception as e:
        print(f"‚ùå Error procesando {ruta_archivo}: {e}")
        return None  # üîπ Devuelve None si hay un error

# =========================================
# üîπ Procesar archivos HTML y guardar en CSV
# =========================================

datos_extraidos = []

# üîπ Procesar archivos HTML
for archivo in os.listdir(carpeta_ofertas):
    if archivo.endswith(".html"):
        datos = procesar_html(os.path.join(carpeta_ofertas, archivo))
        if datos:  # üîπ Solo a√±adir si datos no es None
            datos_extraidos.append(datos)

# üîπ Guardar en CSV
with open(archivo_csv, "w", newline="", encoding="utf-8") as csvfile:
    escritor = csv.writer(csvfile)
    
    # üîπ Escribir encabezados
    escritor.writerow(["Empresa", "Puesto", "Ciudad", "Fecha", "Habilidades"])  
    
    # üîπ Escribir filas de datos
    escritor.writerows(datos_extraidos)

print(f"‚úÖ Archivo CSV generado: {archivo_csv}")